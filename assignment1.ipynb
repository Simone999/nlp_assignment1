{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simone999/nlp_assignment1/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s11XVB5v9JzV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from typing import List, Callable, Dict, Iterable\n",
        "\n",
        "import keras as ks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r \"/content/drive/My Drive/dependency_treebank\" \"dependency_treebank\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yi5UK4UNI6n",
        "outputId": "3d7b235c-d0e2-45a0-f5d6-b15ae3540c56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "structuring dataframe"
      ],
      "metadata": {
        "id": "PGVohBYSOmcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"dependency_treebank\"\n",
        "dataset_path = os.path.join(os.getcwd(), dataset_name)\n",
        "end_train = 100\n",
        "end_validation = 150\n",
        "end_test = 199\n",
        "\n",
        "def create_dataset(start, end, split:str):\n",
        "  tagged_sentences = []\n",
        "  for data_file in range(start, end+1):\n",
        "    filename = os.path.join(dataset_path, \"wsj_%04d.dp\" % data_file)\n",
        "    with open(filename, mode='r', encoding='utf-8') as text_file:  \n",
        "      corpus = text_file.read()\n",
        "      tagged_sentences += corpus.split(\"\\n\\n\")\n",
        "\n",
        "  X = [] # store input sequence\n",
        "  Y = [] # store output sequence\n",
        "  for sentence in tqdm(tagged_sentences):\n",
        "      X_sentence = []\n",
        "      Y_sentence = []\n",
        "\n",
        "      for tagged_word in sentence.rstrip('\\n').split(\"\\n\"):       \n",
        "          entity = tagged_word.split(\"\\t\")\n",
        "          X_sentence.append(entity[0])  # entity[0] contains the word\n",
        "          Y_sentence.append(entity[1])  # entity[1] contains corresponding tag          \n",
        "      X.append(X_sentence)\n",
        "      Y.append(Y_sentence)\n",
        "\n",
        "  assert len(tagged_sentences) == len(X)\n",
        "\n",
        "  df = pd.DataFrame({'sentence':X, 'labels':Y})\n",
        "  df['split'] = split\n",
        "  return df\n",
        "\n",
        "train_set = create_dataset(1, end_train, 'train')\n",
        "val_set = create_dataset(end_train+1, end_validation, 'validation')\n",
        "test_set = create_dataset(end_validation, end_test, 'test')\n",
        "dataset = pd.concat([train_set, val_set, test_set])\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "91ID5ISrBFIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "355671d0-0014-46ce-8519-f0af5ba7f8fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1963/1963 [00:00<00:00, 61186.80it/s]\n",
            "100%|██████████| 1299/1299 [00:00<00:00, 66392.90it/s]\n",
            "100%|██████████| 661/661 [00:00<00:00, 49352.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence  \\\n",
              "0    [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1    [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2    [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3    [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4    [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "..                                                 ...   \n",
              "656  [They, also, said, that, more, than, a, dozen,...   \n",
              "657  [Sen., Kennedy, said, in, a, separate, stateme...   \n",
              "658  [Trinity, Industries, Inc., said, it, reached,...   \n",
              "659                   [Terms, were, n't, disclosed, .]   \n",
              "660  [Trinity, said, it, plans, to, begin, delivery...   \n",
              "\n",
              "                                                labels  split  \n",
              "0    [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1    [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
              "2    [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "3    [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  train  \n",
              "4    [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...  train  \n",
              "..                                                 ...    ...  \n",
              "656  [PRP, RB, VBD, IN, JJR, IN, DT, NN, NNS, VBP, ...   test  \n",
              "657  [NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
              "658  [NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "659                             [NNS, VBD, RB, VBN, .]   test  \n",
              "660  [NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
              "\n",
              "[3923 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f767ed-ab24-42a1-9ffe-8208752b5997\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>[They, also, said, that, more, than, a, dozen,...</td>\n",
              "      <td>[PRP, RB, VBD, IN, JJR, IN, DT, NN, NNS, VBP, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>[Sen., Kennedy, said, in, a, separate, stateme...</td>\n",
              "      <td>[NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>[Trinity, Industries, Inc., said, it, reached,...</td>\n",
              "      <td>[NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>[Terms, were, n't, disclosed, .]</td>\n",
              "      <td>[NNS, VBD, RB, VBN, .]</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>[Trinity, said, it, plans, to, begin, delivery...</td>\n",
              "      <td>[NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3923 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f767ed-ab24-42a1-9ffe-8208752b5997')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20f767ed-ab24-42a1-9ffe-8208752b5997 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20f767ed-ab24-42a1-9ffe-8208752b5997');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(set([word.lower() for sentence in dataset['sentence'] for word in sentence]))\n",
        "num_tags   = len(set([word.lower() for sentence in dataset['labels'] for word in sentence]))\n",
        "\n",
        "print(\"Total number of tagged sentences: {}\".format(len(dataset)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us9lT6vuQ7lK",
        "outputId": "2b69b982-4207-433e-e406-06c5929935a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 3923\n",
            "Vocabulary size: 10947\n",
            "Total number of tags: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot label distributions\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# def flatten(arr):\n",
        "#   return [item for sublist in arr for item in sublist]\n",
        "\n",
        "# def plot_labels_distribution(dataset, title: str):\n",
        "#     train_data = flatten((dataset.loc[dataset['split'] == \"train\"])['labels'])\n",
        "#     val_data = flatten((dataset.loc[dataset['split'] == \"validation\"])['labels'])\n",
        "#     test_data = flatten((dataset.loc[dataset['split'] == \"test\"])['labels'])\n",
        "                    \n",
        "#     classes = flatten(dataset['labels'])\n",
        "#     bins = np.linspace(0, len(classes), len(classes) + 1, dtype='int32')\n",
        "#     plt.title(title)\n",
        "#     plt.hist([train_data, val_data, test_data], bins=bins, label=['train', 'val', 'test'])\n",
        "    \n",
        "#     plt.legend(loc='upper right')    \n",
        "    \n",
        "#     x_ticks_names = classes\n",
        "#     x_ticks_pos = [(i + 0.5) for i in np.arange(len(x_ticks_names))]\n",
        "    \n",
        "#     plt.xticks(x_ticks_pos, x_ticks_names, rotation=90)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# plot_labels_distribution(dataset, 'Tags distribution');"
      ],
      "metadata": {
        "id": "ZjDggP7ZV_JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove embeddings"
      ],
      "metadata": {
        "id": "dMVaMbBDOyJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "def load_embedding_model(model_type: str='glove', embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param model_type: name of the word embedding model to load.\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "    download_path = \"\"\n",
        "    if model_type.strip().lower() == 'word2vec':\n",
        "        download_path = \"word2vec-google-news-300\"\n",
        "\n",
        "    elif model_type.strip().lower() == 'glove':\n",
        "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    elif model_type.strip().lower() == 'fasttext':\n",
        "        download_path = \"fasttext-wiki-news-subwords-300\"\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported embedding model type! Available ones: word2vec, glove, fasttext\")\n",
        "        \n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Word2Vec: 300\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        print('FastText: 300')\n",
        "        raise e\n",
        "\n",
        "    return emb_model\n",
        "\n",
        "embedding_model = load_embedding_model(model_type=\"glove\", embedding_dimension=50)"
      ],
      "metadata": {
        "id": "_D-RYb4L_EiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8091744-3998-4ffc-a900-cd62fdff3296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================================--] 97.5% 64.3/66.0MB downloaded"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vocabulary with Glove vocabulary\n",
        "vocabulary = {k: v.index for k, v in embedding_model.vocab.items()}"
      ],
      "metadata": {
        "id": "G-495Zb7oKG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words(df: pd.DataFrame):\n",
        "  return set(token for tokens in df.sentence.values for token in tokens)\n",
        "\n",
        "class Vectorizer(ks.layers.TextVectorization):\n",
        "  def __init__(self) -> None:\n",
        "     super().__init__()\n",
        "\n",
        "  def expand_vocabulary(self, oov_terms: Iterable[str]):\n",
        "    idx = max(vocabulary.values()) + 1\n",
        "    for term in oov_terms:\n",
        "      vocabulary[term] = idx\n",
        "      idx += 1\n",
        "\n",
        "    return vocabulary\n",
        "\n",
        "def check_OOV_terms(vocabulary: Dict[str, int],\n",
        "                    word_listing: Iterable[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(vocabulary.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)\n",
        "\n",
        "def expand_vocabulary(vocabulary: Dict[str, int], oov_terms: Iterable[str]):\n",
        "  idx = max(vocabulary.values()) + 1\n",
        "  for term in oov_terms:\n",
        "    vocabulary[term] = idx\n",
        "    idx += 1\n",
        "\n",
        "  return vocabulary\n",
        "  \n",
        "\n",
        "word_listing = get_words(train_set)\n",
        "oov_terms = check_OOV_terms(vocabulary, word_listing)\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")\n",
        "\n",
        "print(\"Vocabulary length before expansion:\", len(vocabulary))\n",
        "vocabulary = expand_vocabulary(vocabulary, oov_terms)\n",
        "print(\"Vocabulary length after expansion:\", len(vocabulary))\n",
        "\n",
        "# expand embedding matrix with new (maybe random) vectors, iterating through oov terms\n",
        "\n",
        "# from collections import OrderedDict\n",
        "\n",
        "# def build_vocabulary(df: pd.DataFrame) -> (Dict[int, str],\n",
        "#                                            Dict[str, int],\n",
        "#                                            List[str]):\n",
        "#     \"\"\"\n",
        "#     Given a dataset, builds the corresponding word vocabulary.\n",
        "\n",
        "#     :param df: dataset from which we want to build the word vocabulary (pandas.DataFrame)\n",
        "#     :return:\n",
        "#       - word vocabulary: vocabulary index to word\n",
        "#       - inverse word vocabulary: word to vocabulary index\n",
        "#       - word listing: set of unique terms that build up the vocabulary\n",
        "#     \"\"\"\n",
        "#     idx_to_word = OrderedDict()\n",
        "#     word_to_idx = OrderedDict()\n",
        "    \n",
        "#     curr_idx = 0\n",
        "#     for tokens in tqdm(df.sentence.values):\n",
        "#         for token in tokens:\n",
        "#             if token not in word_to_idx:\n",
        "#                 word_to_idx[token] = curr_idx\n",
        "#                 idx_to_word[curr_idx] = token\n",
        "#                 curr_idx += 1\n",
        "\n",
        "#     word_listing = list(idx_to_word.values())\n",
        "#     return idx_to_word, word_to_idx, word_listing\n",
        " \n",
        "# idx_to_word, word_to_idx, word_listing = build_vocabulary(train_set)\n",
        "# print(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word)}')\n",
        "# print(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx)}')\n",
        "# print(f'[Debug] Some words: {[(idx_to_word[idx], idx) for idx in np.arange(10) + 1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbQQ0Z4gY5e",
        "outputId": "bc3d30c2-041d-4244-cb99-4132cccbe9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 2346 (29.29%)\n",
            "Vocabulary length before expansion: 400000\n",
            "Vocabulary length after expansion: 402346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           vocab_size: int,\n",
        "                           oov_terms: List[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError):\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "0KxkLRMzf6yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = build_embedding_matrix(embedding_model,50,vocabulary,len(vocabulary),oov_terms)\n",
        "embedding_matrix[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk5yNNgA4O4h",
        "outputId": "0ba4defc-d0f5-4856-e4ae-385c8fb7b5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402346/402346 [00:01<00:00, 379624.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
              "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
              "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
              "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
              "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
              "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
              "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
              "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
              "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
              "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Architecture\n",
        "lstm_model = Sequential()\n",
        "# vocabulary size — number of unique words in data\n",
        "# length of vector with which each word is represented\n",
        "lstm_model.add(Embedding(input_dim = len(vocabulary), \n",
        "output_dim = 50, \n",
        "# length of input sequence\n",
        "input_length = 100, \n",
        "# word embedding matrix\n",
        "weights = [embedding_matrix],\n",
        "# True — update embeddings_weight matrix\n",
        "trainable = True \n",
        "))\n",
        "# add an LSTM layer which contains 64 LSTM cells\n",
        "# True — return whole sequence; False — return single output of the end of the sequence\n",
        "lstm_model.add(LSTM(64, return_sequences=True))\n",
        "lstm_model.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
        "#compile model\n",
        "lstm_model.compile(loss      =  'categorical_crossentropy',\n",
        "                  optimizer =  'adam',\n",
        "                  metrics   =  ['acc'])\n",
        "# check summary of the model\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD806mIWs0zT",
        "outputId": "86e17806-9db9-417b-eee0-a875c6075f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 50)           20117300  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 64)           29440     \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 100, 45)          2925      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,149,665\n",
            "Trainable params: 20,149,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_training = lstm_model.fit(embedding_matrix, y_train, batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "3mI-znnbxYI9",
        "outputId": "c8a54c5b-a53e-4647-e766-36745d826374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-162e2706e922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type builtin_function_or_method)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = os.path.join(os.getcwd(),\"Glove\", \"glove.6B.50d.txt\")\n",
        "\n",
        "print (\"Loading Glove Model\")\n",
        "with open(glove_file, encoding=\"utf8\" ) as f:\n",
        "    lines = f.readlines()\n",
        "vocabulary = {}\n",
        "for line in lines:\n",
        "    splits = line.split()\n",
        "    vocabulary[splits[0]] = np.array([float(val) for val in splits[1:]])\n",
        "print (\"Done.\",len(vocabulary.keys()),\" words loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S96Qx5WTSDIZ",
        "outputId": "5b8cb147-f640-42f8-8d50-550e32af592b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Glove Model\n",
            "Done. 400000  words loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findembedding(word):\n",
        "    if word in vocabulary.keys():\n",
        "        embedding = vocabulary[word]\n",
        "    else:\n",
        "        embedding = [0]*50\n",
        "    return embedding\n",
        "\n",
        "def glovesent(sentence):\n",
        "    matrix = [findembedding(word) for word in tokenizer.tokenize(str(sentence))]\n",
        "    matrix = np.array(matrix)\n",
        "    return np.average(matrix, axis=0)\n",
        "\n",
        "\n",
        "glove_X_train = np.array([glovesent(sentence) for sentence in train_set])\n",
        "glove_X_test = np.array([glovesent(sentence) for sentence in test_set])\n",
        "\n",
        "print(glove_X_train.shape)\n"
      ],
      "metadata": {
        "id": "Q92Ni_hCaWay"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}